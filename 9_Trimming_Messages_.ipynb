{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMqjvhl8/P0bCfOtKCdtasb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ARJUN108-verma/LangGraph/blob/main/9_Trimming_Messages_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Trimming Messages:-"
      ],
      "metadata": {
        "id": "lV1XVVZBnTgs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the OpenAI API Key as an Environment Variable"
      ],
      "metadata": {
        "id": "1qAdUAtLncRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mypy_ipython"
      ],
      "metadata": {
        "id": "n6Q5lE7NpD76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bt3BcFe4m9_E"
      },
      "outputs": [],
      "source": [
        "%load_ext dotenv\n",
        "%dotenv\n",
        "%load_ext mypy_ipython"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Relevant Classes and Functions"
      ],
      "metadata": {
        "id": "e5qZldznnn0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph"
      ],
      "metadata": {
        "id": "-wZc7Qw9p2Mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai"
      ],
      "metadata": {
        "id": "E7Ue5vpIqETV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import START, END, StateGraph, add_messages, MessagesState\n",
        "from typing_extensions import TypedDict\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "from langchain_core.messages import AIMessage, HumanMessage, BaseMessage, RemoveMessage\n",
        "from collections.abc import Sequence\n",
        "from typing import Literal, Annotated"
      ],
      "metadata": {
        "id": "MQcWjGOQnq4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the Nodes"
      ],
      "metadata": {
        "id": "wX6wpAyWnx7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(api_key=\"Enter the api key\",\n",
        "                  model = \"gpt-4o\",\n",
        "                  seed = 365,\n",
        "                  temperature = 0,\n",
        "                  max_completion_tokens = 100)"
      ],
      "metadata": {
        "id": "XVn-ov_Qn0hK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_question(state: MessagesState) -> MessagesState:\n",
        "\n",
        "    print(f\"\\n-------> ENTERING ask_question:\")\n",
        "    for i in state[\"messages\"]:\n",
        "        i.pretty_print()\n",
        "\n",
        "    question = \"What is your question?\"\n",
        "    print(question)\n",
        "\n",
        "    return MessagesState(messages = [AIMessage(question), HumanMessage(input())])"
      ],
      "metadata": {
        "id": "NqM7B2mDn7yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(state: MessagesState) -> MessagesState:\n",
        "\n",
        "    print(f\"\\n-------> ENTERING chatbot:\")\n",
        "    for i in state[\"messages\"]:\n",
        "        i.pretty_print()\n",
        "\n",
        "    response = chat.invoke(state[\"messages\"])\n",
        "    response.pretty_print()\n",
        "\n",
        "    return MessagesState(messages = [response])"
      ],
      "metadata": {
        "id": "IXNm8hDtoAZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_another_question(state: MessagesState) -> MessagesState:\n",
        "\n",
        "    print(f\"\\n-------> ENTERING ask_another_question:\")\n",
        "    for i in state[\"messages\"]:\n",
        "        i.pretty_print()\n",
        "\n",
        "    question = \"Would you like to ask one more question (yes/no)?\"\n",
        "    print(question)\n",
        "\n",
        "    return MessagesState(messages = [AIMessage(question), HumanMessage(input())])"
      ],
      "metadata": {
        "id": "1uNMrFAcoEX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trim_messages(state: MessagesState) -> MessagesState:\n",
        "    print(f\"\\n-------> ENTERING trim_messages:\")\n",
        "\n",
        "    remove_messages = [RemoveMessage(id = i.id) for i in state[\"messages\"][:-5]]\n",
        "\n",
        "    return MessagesState(messages = remove_messages)"
      ],
      "metadata": {
        "id": "8W-I4HGOoIOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the Routing Function"
      ],
      "metadata": {
        "id": "dbP0m5t_oJNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def routing_function(state: MessagesState) -> Literal[\"trim_messages\", \"__end__\"]:\n",
        "\n",
        "    if state[\"messages\"][-1].content == \"yes\":\n",
        "        return \"trim_messages\"\n",
        "    else:\n",
        "        return \"__end__\""
      ],
      "metadata": {
        "id": "TvkNjE_foQR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the Graph"
      ],
      "metadata": {
        "id": "K3ls5GWSoRIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph = StateGraph(MessagesState)"
      ],
      "metadata": {
        "id": "KJpjMt4moWD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph.add_node(\"ask_question\", ask_question)\n",
        "graph.add_node(\"chatbot\", chatbot)\n",
        "graph.add_node(\"ask_another_question\", ask_another_question)\n",
        "graph.add_node(\"trim_messages\", trim_messages)\n",
        "\n",
        "graph.add_edge(START, \"ask_question\")\n",
        "graph.add_edge(\"ask_question\", \"chatbot\")\n",
        "graph.add_edge(\"chatbot\", \"ask_another_question\")\n",
        "graph.add_conditional_edges(source = \"ask_another_question\",\n",
        "                            path = routing_function)\n",
        "graph.add_edge(\"trim_messages\", \"ask_question\")"
      ],
      "metadata": {
        "id": "nZ5fxschoZzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_compiled = graph.compile()"
      ],
      "metadata": {
        "id": "Zx6esPzBogky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_compiled"
      ],
      "metadata": {
        "id": "5QpOoylzojZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the Graph"
      ],
      "metadata": {
        "id": "r9AGedASomGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph_compiled.invoke(MessagesState(messages = []))"
      ],
      "metadata": {
        "id": "3v-WIGkLopsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9p_gxj7eqjCX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}